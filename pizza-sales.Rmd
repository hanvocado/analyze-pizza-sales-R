---
title: "PHÂN TÍCH VÀ XÂY DỰNG MÔ HÌNH DỰ ĐOÁN VỚI TẬP DỮ LIỆU BÁN HÀNG PIZZA RESTAURANT SALES"
author:
  - name: "Nguyễn Thị Ngọc Hân"
    mssv: "22133017"
  - name: "Nguyễn Hoàng"
    mssv: "22133020"
  - name: "Võ Triệu Phúc"
    mssv: "22133043"
  - name: "Nguyễn Thị Hồng Thơ"
    mssv: "22151305"
date: "2024-11-04"
output:
  prettydoc::html_pretty:
    theme: leonids
    highlight: github
    toc: true
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readxl)
library(ggplot2)
library(arules)
library(arulesViz)
library(randomForest)
library(broom)
library(scales)
library(gridExtra)
library(lubridate)
library(tseries)
library(forecast)
library(wordcloud)
library(tm)
library(RColorBrewer)
library(xgboost)
library(caret)
library(gbm)
library(ParBayesianOptimization)
```

# Phần 1. Tóm tắt

  Nghiên cứu này dùng ngôn ngữ R để phân tích và xây dựng mô hình dự đoán trên tập dữ liệu bán hàng pizza trong quá khứ. Các biểu đồ Histogram, Boxplot, Line, Bar, Pie, Point, và WordCloud được ứng dụng để trực quan hóa xu hướng trong nhu cầu pizza theo thời gian, tìm ra các thành phần nguyên liệu được thường xuyên sử dụng, thể hiện doanh số, doanh thu của cửa hàng... Đối với doanh số (số lượng pizza bán ra), kiểm định Kruskal-Wallis được dùng để kiểm tra sự biến động doanh số của từng pizza giữa các tháng có đáng kể không. Sau đó các mô hình khác nhau đã được sử dụng để thực hiện dự đoán doanh số: Mô hình Hồi quy tuyến tính được chọn do tính đơn giản và khả năng giải thích dễ dàng, trong khi Rừng ngẫu nhiên và XGBoost được chọn để xử lý các mối quan hệ phức tạp giữa các biến độc lập. Bên cạnh đó, mô hình ARIMA được dùng để dự đoán doanh thu cho 6 tháng tiếp theo.

# Phần 2. Giới thiệu
    
  Dữ liệu được ví như “dầu mỏ của thế kỷ 21” nhờ khả năng thúc đẩy sự đổi mới và cải tiến trong nhiều lĩnh vực. Giá trị của dữ liệu không chỉ nằm ở bản thân các con số, mà còn ở những thông tin có thể khai thác và ứng dụng từ dữ liệu. Đặc biệt trong ngành F&B, khi được thu thập, phân tích và diễn giải đúng cách, dữ liệu bán hàng và hành vi của người tiêu dùng trở thành nguồn tài nguyên chiến lược quan trọng giúp doanh nghiệp đưa ra những quyết định chính xác, giảm thiểu rủi ro và thúc đẩy tăng trưởng. Hơn nữa, phân tích dữ liệu bán hàng sẽ giúp tối ưu hóa hàng tồn kho của doanh nghiệp, giảm tình trạng dư thừa, cũng như có thể tăng số lượng các mặt hàng phổ biến để tránh tình trạng thiếu hàng (sold out) và tối đa hóa doanh số cho doanh nghiệp. 
  
  Cùng với những mục đích trên, trong nghiên cứu này, nhóm chúng em thực hiện phân tích tập dữ liệu bán hàng năm 2015 của một cửa hàng pizza và phát triển các mô hình dự đoán doanh số và doanh thu. Từ đó, có thể rút ra những nhận định hữu ích để hỗ trợ việc ra quyết định kinh doanh, tăng cường hiệu quả hoạt động và xây dựng các chiến lược marketing phù hợp.

# Phần 3. Mục tiêu nghiên cứu
  Để đạt được mục đích đã nêu trên, nhóm chúng em đặt ra các mục tiêu sau:
  
  * Phân tích và trực quan hóa nhu cầu tiêu thụ pizza theo thời gian, xác định rõ xu hướng tiêu thụ theo các giai đoạn cụ thể như mùa, tháng, tuần, ngày trong tuần và giờ trong ngày.
  
  * Phân tích và trực quan hóa tần suất sử dụng, xác định các nguyên liệu dùng nhiều nhất mỗi tháng.
  
  * Phân tích và trực quan hóa doanh số theo kích cỡ bánh, danh mục bánh, xác định các pizza bán chạy nhất cũng như kém phổ biến nhất trong năm 2015. Xác định các yếu tố ảnh hưởng đến doanh số.
  
  * Trực quan hóa sự biến động doanh số của từng pizza qua các tháng và kiểm định có sự khác biệt đáng kể giữa các tháng không.
  
  * Xây dựng mô hình dự đoán doanh số của sản phẩm có độ chính xác trên 80%.
  
  * Phân tích và trực quan hóa doanh thu theo thời gian: doanh thu theo giờ, doanh thu theo ngày, doanh thu theo tháng của cửa hàng trong năm 2015.
  
  * Xây dựng mô hình dự đoán doanh thu trong 6 tháng tiếp theo của cửa hàng có độ chính xác trên 80%.

# Phần 4. Thông tin về tập dữ liệu

```{r}
sales_df <- read_excel("./data/Pizza Sales.xlsx")

head(sales_df)
```
```{r}
str(sales_df)
```

Tập dữ liệu Pizza Sales có tổng cộng 48,620 dòng và 12 cột, cung cấp thông tin chi tiết về các đơn hàng bán pizza. Mỗi dòng tương ứng với một mục trong đơn hàng, được xác định bởi order_details_id, và thuộc về một đơn hàng nhận diện qua order_id. Dữ liệu bao gồm các thông tin quan trọng như ngày và giờ đặt hàng, loại pizza, kích cỡ, số lượng, đơn giá... Cụ thể về thông tin của 12 biến và kiểu dữ liệu tương ứng như sau:

- order_details_id: Kiểu số (numeric). Đây là mã định danh duy nhất cho từng dòng trong tập dữ liệu, đại diện cho mỗi chi tiết đơn hàng.

- order_id: Kiểu số. Đây là mã định danh của mỗi đơn hàng. Nhiều dòng có order_id giống nhau khi chúng cùng thuộc về một đơn hàng.

- pizza_id: Kiểu chuỗi ký tự (character). Đây là mã nhận diện từng pizza.

- quantity: Kiểu số, cho biết số lượng pizza được đặt trong một chi tiết đơn hàng.

- order_date: có kiểu POSIXct, dữ liệu được lưu dưới dạng số nguyên biểu thị số giây kể từ epoch time (01/01/1970), và được hiển thị theo dưới dạng yyyy-mm-dd, cho biết ngày đặt hàng.

- order_time: tương tự như order_date, biến này có kiểu POSIXct, cho biết thời gian đặt hàng. Nhưng dữ liệu có dạng YYYY-mm-dd hh:mm:ss, trong đó ngày tháng năm là không có nghĩa nên cần xử lý trước khi phân tích.

- unit_price: Kiểu số, cho biết đơn giá của một chiếc bánh pizza cụ thể.

- total_price: Kiểu số, cho biết tổng số tiền của dòng chi tiết đơn hàng đó, bằng unit_price × quantity.

- pizza_size: Kiểu chuỗi ký tự, cho biết kích cỡ pizza.

- pizza_category: Kiểu chuỗi ký tự, cho biết pizza được mua thuộc danh mục nào.

- pizza_ingredients: Kiểu chuỗi ký tự, cho biết các nguyên liệu làm nên pizza đó.

- pizza_name: Kiểu chuỗi ký tự, cho biết tên của pizza.

# Phần 5. Tiền xử lý dữ liệu

Sao chép dữ liệu vào biến df để xử lý trên bản sao không gây ảnh hưởng đến dữ liệu gốc.

```{r}
df <- sales_df
```

#### Kiểm tra giá trị thiếu (na) và trùng lặp (duplicate)

* Kiểm tra xem có tồn tại giá trị thiếu (na) ở các cột hay không
```{r}
colSums(is.na(df))
```
Không tồn tại giá trị na.

* Kiểm tra xem có tồn tại duplicate hay không
```{r}
any(duplicated(df))
```
Không có quan sát nào bị trùng lặp

#### Chuyển đổi cột pizza_size, pizza_category thành factor

Xem các giá trị duy nhất của cột pizza_size và pizza_category để xác định thành phần trong levels của factor
```{r}
unique(df$pizza_size)
unique(df$pizza_category)
```
Thực hiện chuyển đổi thành factor
```{r}
df$pizza_size <- factor(df$pizza_size, levels = c("S", "M", "L", "XL", "XXL"))
df$pizza_category <- factor(df$pizza_category)
```

#### Tạo cột order_hour

Dữ liệu của cột order_time là kiểu POSIXct, được lưu trữ dưới dạng số thực đơn vị giây tính từ ngày 1 tháng 1 năm 1970, 00:00:00 UTC, và hiển thị dưới dạng yyyy-mm-dd HH:mm:ss. Nhằm phục vụ mục đích phân tích, em sẽ dựa vào cột này để tạo cột order_hour thể hiện giờ đặt bánh của khách.
```{r}
temp_time <- format(df$order_time, "%H:%M:%S")
df <- df %>% mutate(order_hour = sub("(..):..:..", "\\1", temp_time))

head(df)
```

#### Tạo cột order_weekday

Thêm cột mới tên order_weekday có kiểu factor cho biết khách hàng đã đặt đơn vào thứ mấy.

```{r}
Sys.setlocale("LC_ALL", "C")
df <- mutate(df, order_weekday = weekdays(order_date))
df$order_weekday <- factor(df$order_weekday, levels = c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"))

head(df)
```

#### Tạo cột order_month

Thêm cột mới tên order_month có kiểu factor cho biết khách hàng đã đặt đơn vào tháng nào.

```{r}

df <- mutate(df, order_month = format(order_date, "%B"))

df$order_month <- factor(df$order_month, levels = c("January", "February", "March", "April", "May", "June", "July", "August", "September", "October", "November", "December"))

head(df)
```

#### Tạo data frame chứa dữ liệu của từng đơn đặt hàng

```{r}
by_order_df <- df %>% group_by(order_id) %>% 
  summarise(quantity = sum(quantity), order_date = order_date[1], total_price = sum(total_price), order_hour = order_hour[1], order_weekday = order_weekday[1], order_month = order_month[1]) %>% ungroup()

head(by_order_df)
``` 

# Phần 6. Phân tích dữ liệu:

## 6.1. Phân tích tổng quan

```{r}
by_order_df %>% count()
```
```{r}
by_order_df %>% summarise(no_pizzas = sum(quantity), total_revenue = sum(total_price))
```
Trong năm 2015, cửa hàng có 21350 đơn đặt hàng, bán ra tổng 49574 chiếc bánh pizza với tổng doanh thu là 817860 USD. 

```{r}
by_order_df %>% select(quantity, total_price) %>% summary()
```

Trung bình, mỗi đơn hàng đặt khoảng 2 chiếc bánh pizza, thể hiện phần lớn khách hàng có xu hướng đặt cho gia đình nhỏ hoặc nhóm bạn. Số lượng pizza lớn nhất cho một đơn hàng là 28 chiếc, cho thấy có thể có những đơn đặt hàng số lượng lớn như từ các sự kiện, các buổi tiệc.
\
Dữ liệu cũng cho thấy sự phân hóa trong chi tiêu của khách hàng: đơn hàng thấp nhất là 9.75 USD, cao nhất là 444.4 USD, trong khi trung bình là 32.5 USD. 

> Cửa hàng có thể tận dụng sự đa dạng trong nhóm khách hàng để tạo các chiến lược khuyến mãi phù hợp cho từng nhóm và thiết kế thực đơn, combo hợp lý.

```{r}
by_order_df %>% ggplot(aes(x = total_price)) + geom_histogram(fill = "#FF9999") +
  labs(title = "Distribution of value of an order", x = "Value") +
  theme_minimal()
```

> Biểu đồ histogram của giá trị đơn hàng cho thấy phân phối giá trị lệch phải. Số lượng đơn hàng giá trị hơn 100 USD rất ít. Phần lớn đơn hàng trị giá từ 10 đến 20 USD.
Xu hướng này cho thấy cửa hàng chủ yếu thu hút khách hàng với các đơn hàng có giá trị nhỏ và trung bình, nhưng vẫn có tiềm năng phục vụ các đơn hàng có giá trị lớn.

## 6.2. Phân tích nhu cầu tiêu thụ pizza theo thời gian

Biểu đồ nhu cầu tiêu thụ pizza theo giờ
```{r}
ggplot(data = df, aes(x = order_hour, y = quantity)) +
  geom_col(fill = "blue") +  
  theme_minimal() +
  labs(x = "Hour", y = "Frequency", title = "Pizza Consumption Demand by Hour") +
  theme(plot.title = element_text(hjust = 0.5)
  )
```

* Biểu đồ cho thấy sự phân bố số lượng đơn đặt hàng theo từng giờ trong ngày.

* Giờ có lượng đơn hàng cao nhất là từ 12h đến 13h trưa. Thời gian từ 17h đến 18h cũng có lượng đơn hàng khá cao. Hai khoảng giờ cao điểm này có thể là các thời điểm mà người tiêu dùng có nhiều thời gian rảnh sau giờ làm việc cho bữa ăn trưa và ăn tối. Các khung giờ khác có số lượng đơn hàng giảm dần và thấp nhất là vào khoảng 9h,10h sáng và 23h khuya.

> Dựa vào biểu đồ này, ta có thể quan sát rõ hành vi của người tiêu dùng. Giờ trưa và giờ tan làm có thể là lúc người tiêu dùng có thời gian và nhu cầu đặt thức ăn nhiều hơn. Điều này giúp nhà hàng lập kế hoạch hỗ trợ và chiến lược quảng cáo tốt hơn để thu hút và giữ chân khách hàng.

```{r}
ggplot(data = df, aes(x = order_weekday, y = quantity)) +
  geom_col(fill = "blue") + 
  theme_minimal() +
  labs(x = "Date", y = "Frequency", title = "Pizza Consumption Demand by Day") +
  theme(plot.title = element_text(hjust = 0.5)
  )
```

* Thứ Sáu có nhu cầu cao nhất. Điều này cho thấy mọi người có xu hướng đặt pizza nhiều hơn khi cuối tuần đến gần. Còn lại các ngày khác trong tuần, từ Thứ Hai đến Thứ Năm, nhu cầu tương đối ổn định cho thấy sự tiêu thụ pizza đều đặn trong suốt các ngày làm việc.Nhu cầu thấp nhất vào Chủ Nhật, có khả năng cao khách hàng chuẩn bị cho tuần làm việc sắp tới.

> Biểu đồ cho thấy nhu cầu tiêu thụ pizza tăng cao vào cuối tuần, đạt đỉnh vào Thứ Sáu, có thể do các buổi tụ họp xã hội hoặc xu hướng ăn uống ngoài khi bắt đầu cuối tuần. 

```{r}
ggplot(data = df, aes(x = order_month, y = quantity)) +
  geom_col(fill = "blue") +  
  theme_minimal() +
  labs(x = "Months", y = "Frequency", title = "Pizza Consumption Demand by Month") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1) ,
        plot.title = element_text(hjust = 0.5))  
```

* Các tháng có nhu cầu cao nhất là Tháng Bảy và Tháng Mười Một, cho thấy những khoảng thời gian này có thể có các sự kiện đặc biệt hoặc kỳ nghỉ lễ khiến nhu cầu tăng lên.

* Tháng Hai và Tháng Chín có nhu cầu tiêu thụ pizza thấp hơn so với các tháng khác, có thể do đây là khoảng thời gian sau các kỳ nghỉ lễ hoặc đầu mùa học tập và làm việc.

> Nhìn chung, mức tiêu thụ pizza trong các tháng khá đồng đều, chỉ có sự chênh lệch nhẹ giữa các tháng. Điều này cho thấy pizza của cửa hàng thu hút thực khách quanh năm.
> Nhu cầu tiêu thụ pizza dường như ổn định trong suốt cả năm, với một số tháng có nhu cầu cao hơn, đặc biệt là vào mùa hè (Tháng Bảy) và vào mùa lễ (Tháng Mười Một). Sự tăng giảm nhẹ giữa các tháng có thể phản ánh sự thay đổi trong thói quen ăn uống của người tiêu dùng theo mùa và các dịp lễ.


```{r fig.width=10, fig.height=5}
ggplot(by_order_df, aes(x = order_month, fill = order_weekday)) +
  geom_bar(position = "dodge", color = "black") +  
  scale_fill_brewer(palette = "Pastel1") +         
  theme_minimal() +
  labs(x = "Months", y = "Frequency", title = "Pizza Consumption Demand by Day of the Week for Each Month") + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1) ,
        plot.title = element_text(hjust = 0.5)) 
```

* Sự phổ biến vào cuối tuần: Trong hầu hết các tháng, Thứ Sáu và Thứ Bảy có xu hướng có tần suất đặt hàng cao hơn, cho thấy nhu cầu tiêu thụ pizza tăng vào cuối tuần, có thể do đây là thời điểm mọi người có thời gian rảnh rỗi hoặc tổ chức các buổi tụ họp.
* Biến động theo tháng: Tháng Năm, Tháng Bảy, và Tháng Mười có một số ngày có tần suất cao hơn rõ rệt (đặc biệt vào các ngày cuối tuần), có thể do những tháng này có các sự kiện, kỳ nghỉ hoặc thời tiết thuận lợi cho các hoạt động ăn uống ngoài trời.
* Nhu cầu ổn định giữa tuần: Nhu cầu tiêu thụ pizza vào các ngày giữa tuần (Thứ Hai đến Thứ Năm) ổn định hơn, với ít biến động giữa các tháng. Điều này cho thấy pizza vẫn được tiêu thụ đều đặn nhưng không quá cao vào những ngày đầu tuần và giữa tuần.
* Chênh lệch theo ngày: Sự khác biệt về tần suất giữa các ngày trong tuần lớn nhất vào những tháng mùa hè và mùa thu, cho thấy nhu cầu có thể bị ảnh hưởng bởi mùa hoặc các kỳ nghỉ kéo dài.

> Ta có thể kết luận rằng nhu cầu tiêu thụ pizza thay đổi theo cả tháng và ngày trong tuần, với xu hướng tiêu thụ cao vào các ngày bắt đầu cuối tuần và một số tháng cụ thể có kì nghỉ lễ hoặc thời tiết đẹp. Điều này có thể được sử dụng để dự đoán nhu cầu và tối ưu hóa nguồn cung cho các khoảng thời gian cao điểm trong năm.

```{r, fig.height=6}
by_order_df$order_hour <- as.numeric(by_order_df$order_hour)

order_by_hour <- by_order_df %>%
  group_by(order_weekday, order_hour) %>%
  summarise(frequency = n(), .groups = "drop")

ggplot(data = order_by_hour, aes(x = order_weekday, y = order_hour, size = frequency)) +
  geom_point(color = "steelblue", alpha = 0.7) + 
  scale_size(range = c(3, 15), name = "Frequency") + 
  theme_minimal() +
  labs(
    x = "Day of the Week",
    y = "Hour of the Day",
    title = "Pizza Consumption Distribution by Hour and Day of the Week"
  ) +
  theme(
    plot.title = element_text(hjust = 0.5, size = 16, face = "bold"),
    axis.text.x = element_text(angle = 45, hjust = 1)
  ) +
  scale_y_continuous(
    breaks = seq(9, 23, by = 1), 
    expand = expansion(mult = c(0.05, 0.05))
  )

```
\
Các đơn đặt hàng chủ yếu được đặt từ trưa (11 giờ) đến tối (22 giờ), biểu hiện khoảng thời gian từ trưa đến tối là thời gian cao điểm cho nhu cầu tiêu thụ pizza, đặc biệt vào Thứ Sáu và Thứ Bảy. Ngoài khung giờ này là các điểm dữ liệu ngoài (outliers) cho các đơn hàng vào sáng sớm hoặc đêm muộn. Điều này cho thấy có một số ít đơn đặt hàng trong khoảng thời gian ngoài giờ cao điểm.

> Có thể thấy ít có sự biến động giữa các ngày trong tuần và xu hướng chung là tiêu thụ pizza ổn định từ buổi trưa đến tối. Không có ngày nào có sự biến động lớn hoặc bất thường. Nhu cầu khá ổn định trong cả tuần nhưng có xu hướng cao hơn vào Thứ Sáu và Thứ Bảy

```{r}
ggplot(data = by_order_df, aes(x = order_weekday, y = order_hour, fill = order_weekday)) +
  stat_boxplot(geom = "errorbar", width = 0.25) +
  geom_boxplot(outlier.color = "red", outlier.shape = 16, outlier.size = 2) + 
  theme_minimal() +
  labs(x = "Order Dates", y = "Hour", title = "Pizza Consumption Demand by Hour of the Dates") +
  theme(
    legend.position = "none",
    plot.title = element_text(hjust = 0.5)
  )

```
\
Biểu đồ hộp (boxplot) thể hiện sự phân phối thời gian trong ngày mà pizza được tiêu thụ, được chia theo từng ngày trong tuần. Phân phối phổ biến của thời gian đặt hàng là từ 13h đến 19h tối. Thời gian trung bình đặt hàng các ngày trong tuần là 16h và các ngày cuối tuần (Friday, Saturday, Sunday) có trung vị cao hơn là 17h. Điều này có thể phản ánh vào cuối tuần nhu cầu cao hơn vào buổi tối hoặc các khung giờ muộn. Đặc biệt là Friday, có độ rộng của box lớn nhất, hay mức độ phân tán rộng hơn các ngày khác thể hiện rằng khách hàng đặt pizza vào cả những khung giờ không phổ biến (ngoài giờ cao điểm).

```{r, fig.width=10, fig.height=5}
df_table <- table(by_order_df$order_hour, by_order_df$order_weekday)
df_freq <- as.data.frame(df_table)
colnames(df_freq) <- c("Hour", "Day", "Frequency")


ggplot(df_freq, aes(x = Hour, y = Frequency, fill = Day)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.8))  + 
  scale_fill_manual(values = c("blue", "red", "green", "yellow", "magenta", "cyan", "purple", "orange")) +
  theme_minimal() +
  labs(title = "Pizza Consumption Frequency by Hour of the Day", x = "Hour", y = "Frequency") +
  theme(
    plot.title = element_text(hjust = 0.5),  
    legend.title = element_blank()           
  ) +
  theme(legend.position = "right") +         
  theme(plot.margin = unit(c(1,1,1,1), "cm")) + 
  scale_x_discrete(expand = expansion(mult = c(0.1, 0.1))) 
```

* Thời gian cao điểm: Các giờ cao điểm tiêu thụ pizza tập trung vào buổi trưa (11 giờ - 13 giờ) và buổi tối (17 giờ - 19 giờ). Đỉnh cao nhất của nhu cầu là vào khoảng 12 giờ trưa, với tần suất đặt hàng cao nhất vượt qua 900 đơn vào một số ngày trong tuần, đặc biệt vào các ngày Thứ Ba, Thứ Năm, và Thứ Sáu.

* Sự khác biệt theo ngày trong tuần:
  + Thứ Ba và Thứ Sáu: Có tần suất tiêu thụ pizza cao vào giờ trưa (11 giờ - 13 giờ) và buổi tối (17 giờ - 19 giờ).
  + Thứ Bảy: Tần suất đặt hàng tăng cao vào buổi tối từ 17 giờ đến 19 giờ, có thể do đây là ngày cuối tuần.
  + Chủ Nhật: Tần suất tiêu thụ pizza giảm vào buổi trưa nhưng vẫn có mức độ đặt hàng tương đối ổn định vào buổi tối.
    
* Thời gian ít đơn đặt hàng: Trong các khoảng thời gian sáng sớm (trước 10 giờ) và đêm muộn (sau 21 giờ), tần suất tiêu thụ pizza khá thấp ở tất cả các ngày. Đặc biệt là từ 22 giờ đến 23 giờ, nhu cầu tiêu thụ pizza gần như không đáng kể.

## 6.3. Phân tích nguyên liệu:

### 6.3.1. Phân tích tần suất xuất hiện các từ trong nguyên liệu làm pizza

```{r}
text <- paste(df$pizza_ingredients, collapse = " ")

set.seed(1234) 
wordcloud(words = text, 
          scale = c(4, 0.5), 
          max.words = 121, 
          random.order = FALSE, 
          colors = brewer.pal(8, "Spectral"), 
          random.color = TRUE)
```

* Từ có tần suất lớn nhất là "cheese", một thành phần quan trọng và phổ biến nhất trong pizza. Bên cạnh đó còn có các từ như "garlic", "tomatoes", "peppers",..đây cũng là những nguyên liệu phổ biến. Điều này phù hợp với đặc trưng của món pizza.
* Ngoài ra, một số nguyên liệu ít phổ biến với kích thước từ nhỏ và các loại phô mai đặc biệt (gouda, ricotta) có thể phù hợp với những khách hàng thích hương vị độc đáo nên tần suất rất ít.

### 6.3.2. Phân tích top 10 nguyên liệu sử dụng nhiều nhất trong pizza theo tháng

```{r fig.width=10, fig.height=6}
ingredient_list <- df %>%
  mutate(ingredients = str_split(pizza_ingredients, ", ")) %>%
  unnest(ingredients)

ingredient_matrix <- ingredient_list %>%
  count(order_month, ingredients) %>%
  pivot_wider(names_from = ingredients, values_from = n, values_fill = 0)

ingredient_trends <- ingredient_matrix %>%
  pivot_longer(cols = -order_month, names_to = "ingredient", values_to = "count") %>%
  group_by(order_month, ingredient) %>%
  summarise(total_count = sum(count), .groups = "drop")

top_ingredients <- ingredient_trends %>%
  group_by(ingredient) %>%
  summarise(total_count = sum(total_count)) %>%
  top_n(10, total_count) %>%
  pull(ingredient)

filtered_trends <- ingredient_trends %>%
  filter(ingredient %in% top_ingredients)

ggplot(filtered_trends, aes(x = order_month, y = total_count, color = ingredient, group = ingredient)) +
  geom_line() +
  theme_minimal() +
  labs(
    title = "Top 10 Ingredients Trends Over Time",
    x = "Month",
    y = "Total Count",
    color = "Ingredient"
  ) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

* Garlic là nguyên liệu chủ lực và phổ biến nhất trong công thức pizza, vượt trội hơn các thành phần khác về số lần sử dụng.
Đây có thể do hương vị mạnh mẽ và phù hợp với nhiều loại pizza khác nhau.
 Vị trí thứ hai của Tomatoes phản ánh tầm quan trọng của nguyên liệu này trong nước sốt pizza.
 Xếp tiếp theo là Red Onion và Red Pepper
 Mozzarella Cheese cũng có tần suất phổ biến.
 Các nguyên liệu đứng đầu này có xu hướng biến động thấp nhất vào tháng Hai, tháng Mười, tăng mạnh vào mùa hè (tháng Bảy) và mùa đông (tháng Mười Một).
 
> Nhà hàng có thể dựa vào phân tích để cân nhắc quản lý kho nguyên liệu phù hợp, đặc biệt là các thành phần phổ biến trong các món đặc trưng. Đồng thời, có thể thử nghiệm các loại pizza mới với các nguyên liệu ít phổ biến hơn để thu hút khách hàng thích trải nghiệm hương vị mới.

## 6.4. Phân tích doanh số:

### 6.4.1. Phân tích doanh số theo kích cỡ bánh

* Tổng hợp dữ liệu tính doanh số mỗi tháng của từng loại pizza
```{r}
sales_by_size <- df %>%
  group_by(pizza_size, order_month) %>%
  summarise(
    total_sales = sum(quantity)
  )

head(sales_by_size)
```

* Trực quan hóa bảng số liệu trên bằng biểu đồ tròn
```{r}
ggplot(sales_by_size, aes(x = "", y = total_sales, fill = pizza_size)) +
  geom_bar(stat = "identity") +
  coord_polar(theta = "y") +
  labs(title = "Sales by sizes in 2015") +
  theme_void()
```

  + Bánh pizza cỡ L bán chạy nhất với 18956 chiếc bánh chiếm 38% doanh số, theo sau là cỡ M với 15635 bánh (32%) và cỡ S với 14403 bánh (29%).
  + Bánh size XL và XXL có doanh số rất thấp, cả hai chỉ chiếm chưa tới 2% tổng doanh số của năm 2015.

### 6.4.2. Phân tích doanh số theo danh mục bánh

* Tổng hợp dữ liệu theo danh mục bánh
```{r}
sales_by_category <- df %>%
  group_by(pizza_category, order_month) %>%
  summarise(
    total_sales = sum(quantity)
  )

sales_by_category
```

* Trực quan hóa

```{r}
ggplot(sales_by_category, aes(x = pizza_category, y = total_sales, fill = order_month)) +
  geom_col() +
  labs(title = "Sales by category in 2015",
       fill = "Month") +
  theme_minimal()
```

  + Danh mục bánh Classic bánh chạy nhất với 14888 chiếc. Ba loại còn lại có sự chênh lệch không đáng kể với nhau, cụ thể Supreme là 11987, Veggie là 11649 và thấp nhất là Chicken với 11050 chiếc bánh.
  + Đối với từng danh mục pizza, doanh số không có sự chênh lệch nào đáng kể giữa các tháng.

### 6.4.3. Phân tích doanh số bán hàng của từng bánh pizza

#### Doanh số của từng bánh pizza trong cả năm 2015

* Số bánh pizza cửa hàng kinh doanh

```{r}
sales_by_pizza <- df %>%
  group_by(pizza_name) %>% 
  summarise(total_sales = sum(quantity))

print(length(sales_by_pizza$pizza_name))
```
Cửa hàng kinh doanh 32 bánh pizza khác nhau.

* Trực quan hóa doanh số của từng bánh pizza trong một năm

```{r}
sales_by_pizza %>%
  ggplot(aes(x = total_sales, y = reorder(pizza_name, total_sales))) +
  geom_col(color = "pink", fill = "pink", width = 0.5) +
  labs(title = "Sales by pizza in 2015",
       x = "Quantity",
       y = "Pizza") +
  theme_minimal()
```

  + Pizza bán chạy nhất là The Classic Deluxe Pizza với 2453 bánh.
  + Pizza bán chậm nhất là The Brie Carre Pizza với 490 bánh. Ta có thể dễ dàng nhận thấy sự chênh lệch rất lớn giữa doanh số của nó với các bánh khác, trong đó, chỉ bằng khoảng 50% doanh số của pizza bán chậm thứ hai (The Mediterranean Pizza) và bằng khoảng 20% doanh số của bánh bán chạy nhất.

##### Xem các thuộc tính của ba bánh này để dự đoán nguyên nhân gây ra sự chênh lệch lớn 

```{r}
df %>% select(pizza_name, pizza_size, unit_price, pizza_category, pizza_ingredients) %>% 
  group_by(pizza_name) %>% filter(pizza_name == 'The Classic Deluxe Pizza' | pizza_name == 'The Brie Carre Pizza' | pizza_name == 'The Mediterranean Pizza') %>% unique()
```

  + Có thể nhận thấy sự chênh lệch rất lớn, gần gấp đôi trong giá của The Brie Carre Pizza size S (23.65 USD) và The Classic Deluxe Pizza hay The Mediterranean Pizza size S (12 USD). Do đó em cho rằng *biến unit_price và pizza_size có ảnh hưởng tới doanh số, hơn thế nữa hai biến này là hai biến tương tác*. 

  + Bên cạnh đó, sự khác biệt trong doanh số giữa The Classic Deluxe Pizza và The Mediterranean Pizza mặc dù chúng có mức giá gần như giống hệt nhau cho các kích cỡ. Điều này cho thấy *biến pizza_category cũng ảnh hưởng tới doanh số*. Biến pizza_ingredients sẽ trực tiếp phản ánh tới pizza_cateogry nên em bỏ qua nó.

  + Ngoài ra, The Brie Carre Pizza chỉ có một kích cỡ trong khi đa số bánh còn lại có nhiều kích cỡ, em nghi ngờ độ đa dạng của một bánh pizza ảnh hưởng tới doanh số của nó. Trực quan hóa để kiểm tra:

```{r}
df %>% select(pizza_name, pizza_size) %>% unique() %>% 
  group_by(pizza_name) %>% summarise(no_variants = n()) %>% 
  merge(sales_by_pizza) %>% ggplot(aes(x = no_variants, y = total_sales)) + geom_point()
```

> Không có mối quan hệ tương quan giữa no_variants và total_sales, nghĩa là độ đa dạng của một bánh pizza không ảnh hưởng tới doanh số của nó.

#### Doanh số của từng bánh pizza trong mỗi tháng

```{r}
sales_by_pizza_monthly <- df %>%
  group_by(pizza_name, order_month) %>% 
  summarise(total_sales = sum(quantity))

ggplot(sales_by_pizza_monthly, aes(x = order_month, y = total_sales, color = pizza_name, group = pizza_name)) +
  geom_line() +
  geom_point() +
  labs(title = "Pizza's monthly sales in 2015",
       x = "Month",
       y = "Quantity",
       color = "Pizza Name") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  guides(color = "none")
```
\
Mỗi đường trên biểu đồ thể hiện sự biến động trong doanh số giữa các tháng của một pizza. Có một số bánh có sự biến động trong doanh số một cách đáng chú ý. 

##### Kiểm định doanh số của từng pizza có khác biệt đáng kể giữa các tháng hay không bằng Kruskal-Wallis

Kiểm định Kruskal-Wallis là một phương pháp thống kê phi tham số dùng để so sánh ba nhóm dữ liệu trở lên nhằm xác định xem có sự khác biệt đáng kể nào giữa các nhóm này hay không. Đây là một lựa chọn thay thế cho phân tích phương sai một chiều (ANOVA) khi dữ liệu không tuân theo phân phối chuẩn, phù hợp để kiểm tra sự biến động doanh số của một pizza qua các tháng có ý nghĩa hay không.
\
Trong sales_by_pizza_monthly, mỗi pizza chỉ có một quan sát cho một tháng nên kiểm định Kruskal-Wallis sẽ không có đủ thông tin để so sánh và phát hiện sự khác biệt có ý nghĩa. Do đó em sẽ tổng hợp doanh số của từng pizza theo ngày rồi thực hiện kiểm định cho từng pizza

```{r}
sales_by_pizza_daily <- df %>% group_by(pizza_name, order_date, order_month) %>% summarise(sales = sum(quantity), .groups = 'drop')

kruskal_test <- sales_by_pizza_daily %>%
  group_by(pizza_name) %>%
  summarize(p_value = kruskal.test(sales ~ order_month)$p.value)

print(kruskal_test)
```

Kết quả không có p-value nào có giá trị nhỏ hơn 0.01, nên ta chấp nhận giả thuyết không và kết luận rằng không có sự khác biệt đáng kể trong doanh số giữa các tháng đối với mỗi pizza, hay nói cách khác, doanh số của mỗi pizza tương đối ổn định giữa các tháng trong năm 2015.

## 6.5. Phân tích doanh thu theo thời gian:

Phân tích tổng quan đã cho thấy trong năm 2015, cửa hàng có tổng doanh thu là 817,860 USD. Với giá trị đơn hàng nhỏ nhất là 9.75 USD, lớn nhất là 444.40 USD. Phần dưới đây, sẽ phân tích chi tiết hơn về doanh thu thu được của cửa hàng theo thời gian giờ trong ngày, tuần, và tháng trong năm 2015.

### 6.5.1. Phân tích doanh thu theo giờ trong ngày của một tuần

```{r}
# Tính toán doanh thu theo giờ trong ngày của một tuần:
revenue_by_hour_day <- df %>% 
  group_by(order_hour, order_weekday) %>% 
  summarise(revenue = sum(total_price))

print(revenue_by_hour_day)
```
```{r}
# Biểu đồ đường hiển thị doanh thu theo giờ trong ngày của một tuần:
ggplot(revenue_by_hour_day, aes(x = order_hour, y = revenue, fill=order_weekday, color=order_weekday, group = order_weekday)) +
  geom_line()+
  geom_point(size = 2) +
  facet_wrap(~order_weekday, nrow = 7, scales = "free_y")+
  theme_minimal() +
  labs(
    title = "Revenue by hour of day",
    x = "Time of day",
    y = "Revenue (USD)",
  ) +
  scale_y_continuous(labels = scales::comma)
```

> Biểu đồ cho thấy doanh thu đều chạm đỉnh vào 12h các ngày trong tuần, trừ Thứ 7 và Chủ Nhật. Điều này cho thấy doanh thu sẽ cao vào giờ nghỉ trưa của những ngày đi làm của khách hàng. Ngày Thứ 7 và Chủ Nhật, doanh thu sẽ cao hơn vào thời điểm sau 17h đến 20h. Điều này có thể do khách hàng có xu hướng ăn tối muộn hơn vào cuối tuần. Bên cạnh đó, có sự chênh lệch doanh thu đáng kể vào các thời điểm trong ngày. Cửa hàng có thể triển khai các chương trình khuyến mãi vào các khung giờ thấp điểm để thu hút thêm khách hàng và tăng doanh thu.

### 6.5.2. Phân tích doanh thu một ngày dùng Time Series

* Sao chép dữ liệu vào biến df_ts để xử lý trên bản sao không gây ảnh hưởng đến dữ liệu gốc.

```{r}
df_ts <- df
```

* Chuyển đổi cột order_date thành kiểu Date

```{r}
df_ts$order_date <- as.Date(df_ts$order_date, format = "%Y-%m-%d")
```

* Tính toán doanh thu theo ngày của một năm:  

```{r}
revenue_by_date <- df_ts %>% 
  group_by(order_date) %>% 
  summarise(revenue = sum(total_price))
revenue_by_date
```

* Tạo chuỗi thời gian (time series) với tần suất 365 ngày (Năm 2015 không phải năm nhuận)

```{r}
revenue_ts_date<-ts(revenue_by_date$revenue, start = c(2015, 1), frequency = 365)
# Kiểm tra chuỗi thời gian
print(revenue_ts_date)
```

* Trực quan hóa doanh thu theo ngày với time_series do có nhiều điểm dữ liệu:

```{r}
plot(revenue_ts_date, main = "Revenue of Pizza Over 12 months", xlab = "Time", ylab = "Revenue (USD)", col = "red", lwd = 2)
```
```{r}
revenue_ts_month<-ts(revenue_by_date$revenue, start = c(2015, 1), frequency = 12)
# Kiểm tra chuỗi thời gian
print(revenue_ts_month)
```

> Xu hướng tổng thể: Có sự biến động trong doanh thu theo ngày trong năm 2015 của cửa hàng. Có những ngày doanh thu cao hơn và những ngày doanh thu thấp hơn.
> Doanh thu có sự biến động đáng kể hàng ngày, điều này có thể do nhiều yếu tố như ngày trong tuần, ngày lễ, hoặc các sự kiện đặc biệt. Xu hướng biến động: giảm vào đầu tháng và tăng vào cuối tháng. Doanh thu biến động ít hơn vào những ngày đầu năm. 
> Doanh thu tăng cao bất thường vào những ngày của tháng 5, tháng 7 và khoảng tháng 8. 

### 6.5.3. Phân tích doanh thu theo tháng

```{r}
revenue_by_month <- df %>% 
  group_by(order_month) %>% 
  summarise(revenue = sum(total_price))
revenue_by_month
```

* Trực quan hóa bằng biểu đồ cột để so sánh doanh thu giữa các tháng trong năm: 

```{r}
ggplot(revenue_by_month, aes(x = order_month, y = revenue, group = 1, fill = order_month)) +
  geom_bar(stat = "identity") +
  geom_line(aes(group = 1), color = "red", size = 1) +
  geom_point(color = "red", size = 2) +
  theme_minimal() +
  labs(
    title = "Revenue by month",
    x = "Month",
    y = "Revenue (USD)"
  ) +
  scale_y_continuous(labels = scales::comma)
```
\
Trong năm 2015, doanh thu cao nhất được ghi nhận vào tháng 7 với hơn 70.000 USD. Các tháng có nhu cầu cao nhất là Tháng Bảy và Tháng Mười Một, nhưng Tháng Mười Một lại có doanh thu thấp hơn so với Tháng Năm. Điều này cho thấy rằng dù có nhu cầu tiêu thụ cao vào tháng này, nhưng doanh thu không tương ứng, có thể do các chương trình khuyến mãi hoặc giá bán không phù hợp. 
\
Biểu đồ đường cho thấy doanh thu giữa các tháng về cơ bản không có sự chênh lệch lớn, doanh thu ổn định ở mức trên 60.000 USD mỗi tháng. Điều này cho thấy cửa hàng duy trì được sự ổn định trong doanh thu hàng tháng, tuy nhiên, cần có các chiến lược cụ thể để tối ưu hóa doanh thu trong các tháng có nhu cầu cao.

# Phần 7. Dự đoán doanh số theo sản phẩm:

Mục tiêu của phần này là xây dựng mô hình dự đoán doanh số trong một tháng của một bánh pizza cụ thể, tức là dự đoán xem cửa hàng bán được bao nhiêu bánh pizza đó bằng các đặc trưng của nó cùng với dữ liệu bán hàng trong quá khứ. Em lựa chọn sử dụng hai mô hình là Linear Regression và Random Forest nhằm tận dụng những ưu điểm riêng của mỗi phương pháp và đánh giá hiệu quả của chúng trong bối cảnh dữ liệu hiện có.

* Tổng hợp dữ liệu chứa doanh số mỗi tháng của từng bánh pizza

```{r}
sales_data <- df %>%  group_by(pizza_name, unit_price, pizza_size, pizza_category, order_month) %>% summarise(sales = sum(quantity))

dim(sales_data)
summary(sales_data)
```
Dữ liệu gồm 1091 quan sát, mỗi quan sát thể hiện doanh số của một bánh với kích cỡ xác định (hoặc S hoặc M hoặc L hoặc XL hoặc XXL), đơn giá tương ứng, thuộc danh mục nào và doanh số trong một tháng cụ thể là bao nhiêu. 

Biến sales là biến phụ thuộc mà ta xây dựng mô hình để dự đoán, dao động từ 1 đến 444, với trung bình là 115, đây sẽ là cơ sở để đánh giá mô hình.

Các biến độc lập bao gồm: pizza_name, unit_price, pizza_size và pizza_category. Như đã kiểm định khi phân tích doanh số của từng pizza (6.3.3), doanh số giữa các tháng của một bánh pizza tương đối ổn định, nên không chọn order_month làm biến độc lập.

* Trực quan hóa mối quan hệ giữa doanh số và giá cùng với kích cỡ và danh mục bánh.

```{r}
sales_data %>% 
  ggplot(aes(x = unit_price, y = sales, shape = pizza_size, color = pizza_category)) +
  geom_jitter()
```
\
Biểu đồ cho thấy tác động của giá bán lên sales khác nhau đối với các cỡ bánh khác nhau và các loại bánh khác nhau. Cụ thể như bánh size S giá thấp (~10) có doanh số cao hơn rất nhiều so với bánh size S giá trên 20 USD. Và cùng ở khoảng giá 20 USD nhưng doanh số của các danh mục chênh lệch nhau rất rõ rệt. 

> Vì vậy, ngoài 4 biến độc lập đã nêu (pizza_name, unit_price, pizza_size và pizza_category) thì em sẽ thêm sự tác giữa unit_price và pizza_size, giữa unit_price và pizza_category vào mô hình dự đoán.

## 7.1. Dự đoán doanh số của sản phẩm bằng hồi quy tuyến tính

Hồi quy tuyến tính (Linear Regression) là mô hình thống kê đơn giản và dễ hiểu, dựa trên giả định về mối quan hệ tuyến tính giữa biến độc lập (biến đầu vào) và biến phụ thuộc (biến mục tiêu). Lý do em chọn mô hình này để dự đoán doanh số của sản phẩm vì nó đơn giản và dễ diễn giải, giúp em bước đầu hiểu rõ mức độ và hướng ảnh hưởng của từng biến độc lập đến doanh số sản phẩm. Hơn nữa, hồi quy tuyến tính là một mô hình nền tảng và thường được dùng như tiêu chuẩn so sánh cho các mô hình phức tạp hơn. Khi dữ liệu có dạng tuyến tính hoặc gần tuyến tính, Linear Regression cũng có khả năng mang lại kết quả dự đoán chính xác với chi phí tính toán thấp.

```{r}
lm_sales_model <- lm(sales ~ pizza_name + unit_price * (pizza_size + pizza_category), data = sales_data)
summary(lm_sales_model)
```

F-statistic bằng 55.94 với p-value < 2.2e-16, cho thấy rằng **mô hình hồi quy này có ý nghĩa thống kê**. Cụ thể về ý nghĩa thống kê của từng biến, các biến giả của pizza_category bị thiếu giá trị, nhưng các biến tương tác của nó với unit_price có p-value rất thấp, chứng tỏ **đưa sự tương tác này vào mô hình là hợp lý**. Một số biến dummy của pizza_name, pizza_size có p-value lớn hơn 0.05 nhưng đa số có p-value nhỏ, chứng tỏ **các biến độc lập này có ý nghĩa trong mô hình**.
\
Multiple R-squared bằng 0.6862 và Adjusted R-squared bằng 0.6739 cho thấy **mô hình giải thích khoảng 67% sự biến động của doanh số trong tập dữ liệu**. Mặc dù không quá cao, giá trị này vẫn cho thấy mô hình có thể giải thích một phần đáng kể sự biến động doanh số trong tập dữ liệu.

## 7.2. Dự đoán doanh số theo sản phẩm bằng random forest

Random Forest là một mô hình học máy có giám sát (supervised learning), thường được dùng khi các quan hệ giữa các biến đầu vào và biến mục tiêu là phức tạp hoặc không tuyến tính. Em chọn Random Forest để so sánh với Linear Regression, vì mô hình này có khả năng xử lý và học những mối quan hệ phức tạp giữa các yếu tố ảnh hưởng đến doanh số của sản phẩm như đơn giá, kích cỡ,... mà mô hình tuyến tính không thể nắm bắt.

* Chia tập dữ liệu thành 80% cho huấn luyện và 20% cho kiểm tra.

```{r}
set.seed(123)  
train_index <- sample(nrow(sales_data), 0.8 * nrow(sales_data))
train_data <- sales_data[train_index, ]
test_data <- sales_data[-train_index, ]
```

* Xây dựng mô hình dự đoán doanh số

Trong công thức của mô hình này, em không chỉ định cụ thể sự tương tác giữa các biến độc lập như trong mô hình hồi quy tuyến tính vì random forest có khả năng tự học và nắm bắt các tương tác phức tạp giữa các biến.

```{r}
rf_sales_model <- randomForest(sales ~ pizza_name + unit_price + pizza_size + pizza_category, data = train_data)

rf_sales_model
```

Thông tin về mô hình:
  
  + Đây là một mô hình random forest cho bài toán hồi quy, tức là nó dự đoán giá trị liên tục, trong bài toán này là doanh số của sản phẩm.
  + Mô hình bao gồm 500 cây quyết định. Số cây càng lớn thì mô hình càng trở nên ổn định và chính xác hơn, nhưng cũng sẽ tốn thời gian huấn luyện và yêu cầu bộ nhớ cao hơn.
  + Số biến được thử ở mỗi lẫn phân tách là 1, nghĩa là với mỗi lần phân chia trong các cây, thuật toán sẽ ngẫu nhiên chọn 1 biến (trong tổng số 3 biến: unit_price, pizza_size, và pizza_category) và tính điểm phân chia tốt nhất dựa trên chúng.
  + Từ giá trị trung bình bình phương phần dư (Mean of squared residuals), ta có sai lệch trung bình giữa các giá trị dự đoán và giá trị thực tế của doanh số là khoảng 15 đơn vị (RMSE), bằng 13% giá trị trung bình của sales.
  + Mô hình đã giải thích được 69% sự biến động của doanh số dựa trên các đặc trưng đầu vào.

> Mô hình này khá đáng tin cậy (RMSE không quá cao) nhưng khả năng dự đoán vẫn còn khá thấp.

### Tối ưu hóa mô hình

Hiện tại, số cây quyết định của mô hình là 500 và số biến được thử tại mỗi lần phân tách là 1.

* Kiểm tra ngưỡng cây tối ưu chưa:
    
```{r}
plot(rf_sales_model)
```
\
Biểu đồ cho thấy **500 cây là phù hợp** vì error tại đây đã rất nhỏ và gần như không còn giảm nữa.

* Sử dụng tuneRF để tìm tham số mtry tối ưu cho mô hình:

```{r}
tune_rf <- tuneRF(sales_data[, -which(names(sales_data) == "sales")], sales_data$sales)
```
\
OOB Error rate là lỗi ngoài bộ dữ liệu huấn luyện, phản ánh độ chính xác của mô hình. Dự vào biểu đồ kết hợp với việc dữ liệu có 4 biến độc lập, mà nhiều biến các sự tương tác phức tạp với nhau nên em **chọn mtry = 2 để tối ưu mô hình**.

* Thực hiện tối ưu mô hình với tham số đã chọn:

```{r}
rf_sales_model <- randomForest(sales ~ pizza_name + unit_price + pizza_size + pizza_category, data = train_data, mtry = 2)

rf_sales_model
```

> Từ Mean of squard residuals ta có RMSE bằng khoảng 8.6, giảm 6 đơn vị so với mô hình random forest ban đầu. Và R^2^ bằng 90%, tăng 20%. Chứng tỏ giá trị mtry = 2 là giá trị phù hợp để tối ưu mô hình. Chọn đây là mô hình dự đoán cuối cùng.

* Dự đoán doanh số trên tập dữ liệu kiểm tra

```{r}
predicted_sales <- predict(rf_sales_model, newdata = test_data)

head(predicted_sales)
```

* Kiểm tra độ chính xác

```{r}
actual_values <- test_data$sales

# Tính R2 (R-squared)
ss_total <- sum((actual_values - mean(actual_values))^2)
ss_residual <- sum((actual_values - predicted_sales)^2)
r_squared <- 1 - (ss_residual / ss_total)
cat("R-squared: ", r_squared)
```

Mô hình đã giải thích được 90% sự biến thiên của sales trong tập dữ liệu kiểm tra.

* Tính toán lỗi RMSE (Root Mean Squared Error)

```{r}
rmse <- sqrt(mean((predicted_sales - actual_values)^2))
cat("RMSE: ", rmse)
```

Trung bình, giá trị doanh số dự đoán và giá trị thực tế của nó chênh lệch nhau khoảng 9 đơn vị, bằng khoảng 8% giá trị trung bình của sales.

> Mô hình có R-squared cao khoảng 90% trên cả tập dữ liệu huấn luyện và tập kiểm tra, nên có thể kết luận rằng mô hình không bị overfitting và đạt hiệu quả dự đoán rất tốt. Bên cạnh đó, sai số dự đoán (RMSE) nhỏ cho thấy đây là mô hình rất đáng tin cậy để dự đoán doanh số.

## 7.3 Dự đoán doanh số bằng mô hình XGBoost

Ở mô hình Random Forest xây dựng các cây quyết định độc lập song song và kết hợp chúng bằng trung bình hoặc biểu quyết đa số, dẫn đến mô hình ít nhạy cảm hơn với lỗi nhưng cũng có thể bỏ qua các mẫu quan trọng. Boosting, với khả năng học có trọng số, có xu hướng phù hợp hơn để nắm bắt các mối quan hệ phi tuyến phức tạp giữa các đặc trưng và mục tiêu, đặc biệt khi dữ liệu có nhiễu hoặc cần tối ưu hóa sâu hơn.

* Tạo dataframe phù hợp và thực hiện tiền xử lý để phù hợp với yêu cầu của mô hình GBM.

```{r}
 sale_data <- df %>%
  mutate(order_month = floor_date(as.Date(order_date), "month")) %>% # ngay dau cua thang
  group_by(pizza_name, unit_price, pizza_size, pizza_category, order_month) %>%
  summarise(sales = sum(quantity), .groups = 'drop')
sale_data
```

* Lý do sử dụng mô hình XGboost:

Vì ưu điểm nổi bật của XGBoost nằm ở khả năng tự động xử lý các biến phân loại (sau khi được mã hóa), khả năng học phi tuyến tính từ các đặc trưng, và tính năng điều chỉnh quá trình huấn luyện thông qua các tham số như learning rate (eta), max_depth, và subsampling. Trong bài toán này, XGBoost không chỉ sử dụng các đặc trưng đơn giản như giá bánh và thời gian, mà còn tận dụng các biến phân loại như loại bánh, kích thước, và danh mục, giúp mô hình khai thác được nhiều mối quan hệ tiềm ẩn trong dữ liệu.

```{r}
# Biến đổi cột thời gian và mã hóa biến phân loại
sale_data <- sale_data %>%
  mutate(
    order_month_num = as.numeric(order_month), # Chuyển order_month thành số
    pizza_name = as.factor(pizza_name)
  )

# Chuyển đổi biến phân loại thành dạng số
sale_data$encoded_name <- as.numeric(sale_data$pizza_name)
sale_data$encoded_size <- as.numeric(sale_data$pizza_size)
sale_data$encoded_category <- as.numeric(sale_data$pizza_category)

# Tạo tập dữ liệu đầu vào (features) và đầu ra (target)
features <- sale_data %>%
  select(order_month_num, unit_price, encoded_name, encoded_size, encoded_category)

target <- sale_data$sales

summary(sales_data)
```


* Chuẩn bị dữ liệu cho mô hình XGBoost

```{r}
#Chia tập dữ liệu thành train và test
set.seed(123)
train_index <- createDataPartition(target, p = 0.8, list = FALSE)
train_features <- as.matrix(features[train_index, ])
test_features <- as.matrix(features[-train_index, ])
train_target <- target[train_index]
test_target <- target[-train_index]

dtrain <- xgb.DMatrix(data = train_features, label = train_target)
dtest <- xgb.DMatrix(data = test_features, label = test_target)
```

* Chuẩn bị tham số cho mô hình XGboost

```{r}
set.seed(123)
params <- list(
  objective = "reg:squarederror", # Hồi quy
  eta = 0.1,                      # Learning rate 0.1
  max_depth = 6                   # Độ sâu cây 6 
)
```

* Huấn luyện mô hình XGBoost

```{r}
xgb_model <- xgboost(
  data = dtrain,
  params = params,
  nrounds = 100,   
  verbose = 0
)

# Dự đoán và đánh giá
preds <- predict(xgb_model, dtest)

```

* Kiểm tra độ chính xác của mô hình 

```{r}

# Tạo DataFrame từ dữ liệu thực tế và dự đoán
comparison <- data.frame(
  Actual = test_target,
  Predicted = preds
)

# Tính toán các giá trị cần thiết
ss_res <- sum((comparison$Actual - comparison$Predicted)^2) # SS_res
ss_tot <- sum((comparison$Actual - mean(comparison$Actual))^2) # SS_tot

# Tính RMSE
rmse <- sqrt(mean((preds - test_target)^2))
cat("RMSE:", rmse, "\n")

# Tính R-squared
r_squared <- 1 - (ss_res / ss_tot)
cat("R-squared:", r_squared, "\n")

comparison
```

**Tối ưu hóa mô hình**

Em sẽ sử dụng Bayesian Optimization (Tối ưu hóa Bayes) để tìm kiếm giá trị tối ưu cho hai tham số lambda (L2 regularization) và alpha (L1 regularization) trong mô hình XGBoost.

+ lambda (λ) và alpha (α) là hai tham số quan trọng liên quan đến việc điều chỉnh độ phức tạp của mô hình, đặc biệt là trong quá trình regularization (chuẩn hóa)

+ Tạo hàm tối ưu hóa xgb_bayes ( Đây là hàm mục tiêu được sử dụng bởi Bayesian Optimization để đánh giá hiệu quả của từng tổ hợp giá trị tham số.)

```{r}
xgb_bayes <- function(lambda, alpha) {
  params <- list(
    objective = "reg:squarederror",
    eta = 0.1,
    max_depth = 6,
    lambda = lambda,
    alpha = alpha
  )
  model <- xgb.train(
    params = params,
    data = dtrain,
    nrounds = 100,
    watchlist = list(val = dtest),
    early_stopping_rounds = 10,
    verbose = 0
  )
  list(Score = -model$best_score, Pred = model$best_iteration)
}
```

+  Chỉ định phạm vi giá trị có thể thử nghiệm cho các tham số lambda & alpha.
```{r}
bounds <- list(
  lambda = c(0, 10),
  alpha = c(0, 10)
)

```

+ Gọi hàm tối ưu hóa bayesOpt

```{r}
set.seed(123)
opt <- bayesOpt(
  FUN = xgb_bayes,
  bounds = bounds,
  initPoints = 5,
  iters.n = 10,
  verbose = 0
)

opt$scoreSummary

```
**Lấy dòng có Score tốt nhất** 
```{r}

best_row <- opt$scoreSummary[which.max(opt$scoreSummary$Score), ]
print(best_row)

```
 
 **Tạo danh sách tham số đã tối ưu nhất**
```{r}
best_lambda <- best_row$lambda
best_alpha <- best_row$alpha
# Thiết lập Grid Search với L1 (alpha) và L2 (lambda)
# Tạo danh sách tham số
params <- list(
  objective = "reg:squarederror",
  eta = 0.1,
  max_depth = 6,
  gamma = 1,
  colsample_bytree = 0.8,
  subsample = 0.9,
  min_child_weight = 1,
  alpha = best_alpha,           # L1 regularization
  lambda = best_lambda           # L2 regularization
)
```
**Tìm nround tốt nhất bằng cross-validation**
```{r}
# Thực hiện Cross-Validation
cv_results <- xgb.cv(
  params = params,
  data = train_features,
  label = train_target,
  nrounds = 500,
  nfold = 5,
  metrics = "rmse",
  verbose = 0,
  early_stopping_rounds = 10
)

# Số cây tốt nhất
best_nrounds <- cv_results$best_iteration
best_nrounds
```

**Huấn luyện mô hình cuối cùng**

```{r}

xgb_model_tuned <- xgboost(
  params = params,
  data = train_features,
  label = train_target,
  nrounds = best_nrounds,
  verbose = 0,

)
```

**Thưc hiện dự đoán và kkiểm tra độ chính xác**
```{r}
# Dự đoán trên tập kiểm tra
predictions <- predict(
  xgb_model_tuned,
  newdata = test_features
)

# Tính RMSE
rmse <- sqrt(mean((test_target - predictions)^2))
cat("RMSE:", rmse, "\n")

# Tính R-squared
ss_res <- sum((test_target - predictions)^2)
ss_tot <- sum((test_target - mean(test_target))^2)
r_squared <- 1 - (ss_res / ss_tot)
cat("R-squared:", r_squared, "\n")


```

## 7.4. Kết luận

Trong bài toán này, mô hình hồi quy tuyến tính có độ chính xác thấp nhất (~67%), trong khi hai mô hình Random forest và XGBoost đều cho sai số dự đoán nhỏ tương đương nhau và đều có độ chính xác cao khoảng 90%. Vì vậy, em chọn random forest là mô hình cuối cùng dùng để dự đoán doanh số của sản phẩm. Quyết định này là do khi hai mô hình có hiệu suất tương đương thì nên chọn mô hình đơn giản hơn để dễ hiểu, bảo trì, triển khai, ít nguy cơ overfitting và yêu cầu ít tài nguyên tính toán hơn. Trong bài toán này, Random forest có khả năng tổng quát hóa tốt hơn mà không cần điều chỉnh quá nhiều, và các cây quyết định của nó được xây dựng một cách độc lập với nhau nên có tốc độ huấn luyện nhanh và ít nhạy cảm với nhiễu trong tập dữ liệu hơn XGBoost.\
Ngoài ra, mô hình random forest sau khi được tối ưu đã dự đoán doanh số của sản phẩm tốt hơn rất nhiều so với mô hình hồi quy tuyến tính vì nó có khả năng nắm bắt các mối quan hệ phi tuyến tính và tương tác phức tạp giữa các biến độc lập mà mô hình hồi quy tuyến tính chưa mô tả được. Mô hình random forest còn có khả năng xử lý hiệu quả biến phân loại nhiều mức một cách tự nhiên khi xây dựng các cây quyết định, trong khi đó mô hình hồi quy tuyến tính sẽ dùng kỹ thuật one hot encoding để tạo biến giả, tăng độ phức tạp của mô hình và có thể gây ra vấn đề đa cộng tuyến. Hơn nữa, random forest ít bị ảnh hưởng bởi giá trị ngoại lai (outliers) nhờ lấy trung bình của nhiều cây quyết định, và không yêu cầu các giả định phân phối nghiêm ngặt, phù hợp với tính chất dữ liệu trong bài toán này.

# Phần 8. Dự đoán doanh thu trong 6 tháng tiếp theo bằng mô hình ARIMA: 

Mục tiêu của mô hình là dự báo doanh thu theo ngày của chuỗi doanh thu theo ngày(revenue_ts_date) từ dữ liệu được khai thác trong giai đoạn từ 01/01/2015 đến 20/12/2015 theo phương pháp ARIMA. 

* Khi xây dựng mô hình ARIMA, cần phải xem xét tham số p,d,q. Đầu tiên cần phải lựa chọn tham số phù hợp cho mô hình ARIMA (p,d,q):
  + p: Số bậc của phần tự hồi quy (Auto-Regressive). Nó đại diện cho số lượng các giá trị trước đó của chuỗi thời gian được sử dụng để dự đoán giá trị hiện tại. 
  + d: Bậc sai phân cần thực hiện để chuỗi thời gian trở nên dừng (stationary). Chuỗi thời gian được gọi là dừng nếu giá trị kỳ vọng và phương sai của nó không thay đổi theo thời gian. Sai phân giúp loại bỏ xu hướng (trend) và tính mùa vụ (seasonality) trong dữ liệu. d đại diện cho số lần sai phân để chuỗi thời gian trở nên dừng. 
  > Phép sai phân là quá trình tính toán hiệu số giữa các giá trị liên tiếp trong chuỗi thời gian. Phép sai phân là quá trình tính toán hiệu số giữa các giá trị liên tiếp trong chuỗi thời gian. 
  + q: Số bậc của phần trung bình trượt (Moving Average).Nó đại diện cho số các nhiễu (error terms) trong quá khứ được sử dụng để dự đoán giá trị hiện tại.
  * Đầu tiên, cần kiểm tra tính dừng của chuỗi thời gian: 
  * Một chuỗi thời gian dừng có các đặc tính thống kê như trung bình và phương sai không thay đổi theo thời gian, điều này rất quan trọng cho việc xây dựng các mô hình dự báo như ARIMA. Kiểm tra tính dừng bằng ADF test (Augmented Dickey-Fuller): 

```{r}
adf_test <- adf.test(revenue_ts_date)
print(adf_test)
```

> Giá trị p-value < 0.05, chúng ta bác bỏ giả thuyết 0 rằng chuỗi thời gian không dừng. Nghĩa là chấp nhận giả thuyết c  huỗi thời gian dừng. 
> Chuỗi thời gian dừng nên lấy d = 0
* Tìm tham số phù hợp cho mô hình ARIMA: 
* Xác định p, q dựa vào ACF (Auto-Correlation Function) và PACF (Partial Auto-Correlation Function):
\

 * Xác định tham số p, q:  
  q: Số lượng độ trễ có ý nghĩa trong ACF.
  
* Xác định hệ số tự tương quan (AFC) thông qua biểu đồ AFC. ACF đo lường tương quan giữa các quan sát hiện tại và các quan sát trễ (lags) 
```{r}
# Vẽ biểu đồ ACF cho chuỗi thời gian revenue_ts_date
acf(revenue_ts_date, main = " ACF chart for revenue_ts_date time series", lag.max = 100)
```

\
Trục hoành là độ trễ, trục tung là giá trị của hệ số tự tương quan tương ứng với độ trễ. Dãi màu xanh là khoảng tin cậy 95% để giá trị hệ số tự tương quan bằng 0. Nếu tại một độ trễ nhỏ nhất mà đoạn thẳng (vuông góc với trục hoành) mà độ dài đại diện cho giá trị của hệ số tự tương quan nằm ngoài khoảng tin cậy thì đó chính là độ trễ phù hợp lớn nhất mà ta nên lựa chọn cho quá trình trung bình trượt MV(q). Bậc q không nên quá lớn. 
\
 p: Số lượng độ trễ (lags) có ý nghĩa trong PACF.

* Xác định p thông qua biểu đồ PACF: 
```{r}
pacf(revenue_ts_date, main = "PACF chart for revenue_ts_date time series")
```

\
Tương tự như ACF, thông qua một biểu đồ PACF về giá trị các hệ số tương quan riêng phần tương ứng với các độ trễ khác nhau, chúng ta sẽ tìm ra được các bậc tự do phù hợp. Đó chính là vị trí mà giá trị của hệ số tương quan riêng phần nằm ngoài ngưỡng tin cậy 95% của giả thuyết hệ số tương quan riêng phần bằng 0.
Quan sát các spike (điểm vượt ngưỡng):
Có một spike lớn ở lag rất nhỏ (gần 0.01).
Các spike tiếp theo (ở lag khoảng 0.02 và 0.04) cũng vượt ngưỡng nhưng nhỏ hơn.
Sau đó, các giá trị PACF giảm dần và nằm trong khoảng tin cậy (giữa hai đường xanh).
Nhận định:
Spike lớn đầu tiên trong PACF cho thấy một mô hình tự hồi quy.
Sau lag 0.04, các giá trị PACF dường như không còn đáng kể.

* Tự động chọn tham số ARIMA (p,d,q):

```{r}
auto_model <- auto.arima(revenue_ts_date, seasonal=TRUE, stepwise=FALSE, approximation=FALSE)
# Dùng  stepwise=FALSE để tìm kiếm tăng độ chính xác trong việc tìm kiếm mô hình nhưng tiêu tốn thời gian tính toán nhiều hơn.
# approximation=FALSE sử dụng phương pháp chính xác (exact likelihood estimation), đảm bảo mô hình được chọn là tốt nhất dựa trên các tiêu chí như AIC, AICc, hoặc BIC, nhưng thời gian tính toán sẽ tăng đáng kể.
summary(auto_model)
```

> Tham số được chọn là ARIMA (2,0,2). Giá trị của AIC càng nhỏ thì mô hình càng phù hợp. ACF1 gần 0 cho thấy phần dư không có tự tương quan đáng kể, điều này là tốt vì nó cho thấy mô hình đã nắm bắt được cấu trúc của chuỗi thời gian.

* Để kiểm tra sự phù hợp của mô hình ARIMA, có thể kiểm tra các giá trị residuals (phần dư) để đảm bảo rằng mô hình không có vấn đề với giả thuyết chuỗi thời gian.

```{r}
# Kiểm tra phần dư của mô hình ARIMA
checkresiduals(auto_model)
```

> Phân phối phần dư dường như hơi lệch với đuôi dài, đặc biệt có một số phần dư cực lớn. Điều này cho thấy phân phối của phần dư không hoàn toàn tuân theo chuẩn. Các giá trị tự tương quan của phần dư không nằm hoàn toàn trong giới hạn tin cậy (đường chấm xanh), đặc biệt ở một số độ trễ (lags).

* Kiểm tra lại với các mô hình ARIMA khác nhau: 

```{r}
# ARIMA(2,0,0)
model_200 <- arima(revenue_ts_date, order = c(2, 0, 0))
summary(model_200)

# ARIMA(2,0,2)
model_202 <- arima(revenue_ts_date, order = c(2, 0, 2))
summary(model_202)

# ARIMA(5,0,0)
model_500 <- arima(revenue_ts_date, order = c(5, 0, 0))
summary(model_500)

# ARIMA(2,1,2)
model_212 <- arima(revenue_ts_date, order = c(2, 1, 2))
summary(model_212)
```

> Mô hình ARIMA (2,0,2) vẫn tốt hơn. 

* Sau khi đã tìm ra được mô hình ARIMA tốt nhất. Chúng ta sẽ dự báo cho khoảng thời gian tiếp theo.

* Dự đoán doanh thu trong 6 tháng (180 ngày) tiếp theo. Do điểm dữ liệu doanh thu theo tháng quá ít để xây dựng mô hình, nên sẽ dự đoán theo ngày, với số ngày là 180 ngày.    

```{r}
forecast_values <- forecast(auto_model, h = 180, level = c(80))
# Hiển thị dự đoán
print(forecast_values)
```
+ Trực quan hóa số liệu dự đoán:

```{r}
plot(forecast_values, main = "
Forecast revenue for the next 6 months", xlab = "Time", ylab = "Revenue (USD)")
lines(revenue_ts_date, col = "blue", lwd = 2)
```

**Nhận xét:**

1. Xu hướng dự báo: Doanh thu pizza trong 6 tháng dự báo có xu hướng ổn định, không tăng hoặc giảm mạnh theo thời gian. Điều này thể hiện qua đường trung bình (màu xanh), dao động quanh một mức giá trị cố định, không có sự thay đổi đáng kể về xu hướng. 

2. Biến động của dữ liệu: Trong dữ liệu lịch sử, doanh thu pizza có những giai đoạn dao động lớn và xuất hiện các đỉnh cao đột ngột. Tuy nhiên, dự báo không phản ánh các biến động lớn đó, mà chỉ nhắm đến mức trung bình chung, làm giảm khả năng dự đoán các đột biến doanh thu (nếu có).

3. Về độ tin cậy: Với khoảng tin cậy khá rộng, đặc biệt ở cuối giai đoạn dự báo, điều này có thể ám chỉ rằng mô hình gặp khó khăn trong việc nắm bắt toàn bộ đặc điểm của dữ liệu, đặc biệt là những biến động bất thường trong lịch sử.
Do đó, dự đoán này nên được sử dụng thận trọng, đặc biệt trong việc ra quyết định dài hạn.

4. Ổn định: Nếu xu hướng trung bình tiếp tục, doanh nghiệp có thể dự đoán doanh thu tương đối ổn định mà không cần phải đối mặt với biến động lớn trong ngắn hạn nhưng cũng có rủi ro tiềm ẩn: Các sự kiện bất thường (như khuyến mãi, nhu cầu mùa cao điểm) có thể không được phản ánh đầy đủ trong mô hình. Điều này cần được cân nhắc khi lập kế hoạch kinh doanh.

# Phần 9. Kết luận:

Mục tiêu của đề tài là thực hiện bài toán phân tích dữ liệu và xây dựng mô hình dự đoán với ngôn ngữ R trên tập dữ liệu bán hàng của một cửa hàng pizza. Đồ án của nhóm đã đạt được mục tiêu đề ra bằng cách: Hiểu dữ liệu và bài toán; Tiền xử lý dữ liệu như kiểm tra giá trị thiếu, chuyển sang kiểu dữ liệu phù hợp, tạo các biến mới cần thiết...; Cung cấp các đánh giá và trực quan hóa kết quả phân tích nhu cầu tiêu thụ pizza, nguyên liệu, doanh số, doanh thu bằng nhiều loại biểu đồ đa dạng; Xây dựng được mô hình dự đoán doanh số với độ chính xác cao và sai số nhỏ; Dự đoán doanh thu trong 6 tháng tiếp theo bằng mô hình ARIMA. Mặc dù đồ án đã sử dụng một tập dữ liệu khá lớn, tuy nhiên thông tin dữ liệu là từ các đơn đặt hàng pizza trong năm 2015, mang tính chất thực hành phân tích. Ngoài ra, tập dữ liệu chứa ít thông tin về khách hàng, gây khó khăn trong việc thực hiện các phân tích liên quan như phân khúc khách hàng, phân tích hành vi mua sắm. Qua những hạn chế đã đề cập, để phát triển đề tài này nhóm có thể thu thập nhiều thông tin liên quan đến khách hàng, sử dụng dữ liệu mới nhất từ các hệ thống bán hàng thời gian thực nhằm nâng cao giá trị của các phân tích.

# Phần 10. Tài liệu tham khảo:

# Phần 11. Đóng góp:

## 11.1. Bảng phân công nhiệm vụ

| STT |   Mã SV   |     Họ và tên    |                Nhiệm vụ                                                                              |
|-----|-----------|------------------|------------------------------------------------------------------------------------------------------|
|  1  |  22133017 | Nguyễn Thị Ngọc Hân | - Lập kế hoạch và Phân công. \
- Viết tóm tắt (Phần 1). \
- Viết giới thiệu (Phần 2). \
- Phân tích doanh số (6.4). \
- Dự đoán doanh số bằng mô hình hồi quy tuyến tính (7.1) và random forest (7.2); Kết luận phần dự đoán doanh số (7.4).  \
- Format R Markdown. |
|  2  |  22133020 | Nguyễn Hoàng | - Phân tích nhu cầu tiêu thụ pizza theo thời gian (6.2) \
- Phân tích nguyên liệu (6.3). \
- Viết kết luận (Phần 9). \
- Tổng hợp file Word. |
|  3  |  22133043 | Võ Triệu Phúc  | - Thông tin về tập dữ liệu (Phần 4). \
- Tiền xử lý dữ liệu (Phần 5) \
- Dự đoán doanh số bằng mô hình XGBoost (7.3).|
|  4  |  22151305 | Nguyễn Thị Hồng Thơ  | - Phân tích tổng quan dữ liệu (6.1). \
- Phân tích doanh thu (6.5). \
- Dự đoán doanh thu theo thời gian (Phần 8). \
- Tổng hợp file PowerPoint. |
		
## 11.2. Thành viên nhận xét và đánh giá

### Nguyễn Thị Ngọc Hân

| Thành viên      | Nhận xét     | Đánh giá (%)     |
|------------|-----------|-----------|
| Nguyễn Hoàng     | Hoàn thành đúng tiến độ. Sử dụng đa dạng biểu đồ, nhận xét các biểu đồ rất chi tiết. | 100 |
| Võ Triệu Phúc     | Giải thích tập dữ liệu bằng AI nhưng không kiểm tra lại, xác định sai kiểu dữ liệu của order_date, unit_price,... Trễ hạn của nhóm. Xây dựng được mô hình XGBoost nhưng chưa nhận xét. | 85 |
| Nguyễn Thị Hồng Thơ    | Hoàn thành tốt nhiệm vụ. | 100 |

### Nguyễn Hoàng

| Thành viên      | Nhận xét     | Đánh giá (%)     |
|------------|-----------|-----------|
| Nguyễn Thị Ngọc Hân     | Phân công việc cụ thể cho thành viên, đảm bảo tiến độ của nhóm. Hoàn thành tốt nhiệm vụ | 100 |
| Võ Triệu Phúc     | Hoàn thành nhiệm vụ | 100 |
| Nguyễn Thị Hồng Thơ    | Hoàn thành tốt nhiệm vụ | 100 |

### Nguyễn Thị Hồng Thơ

| Thành viên      | Nhận xét     | Đánh giá (%)     |
|------------|-----------|-----------|
| Nguyễn Hoàng     | Hoàn thành đúng tiến độ. Nhận xét biểu đồ rất chi tiết | 100 |
| Võ Triệu Phúc     | Hoàn thành nhiệm vụ | 100 |
| Nguyễn Thị Ngọc Hân   | Phân công việc cụ thể cho nhóm, kiểm tra lại các việc thường xuyên. Hoàn thành đúng tiến độ. | 100 |

